{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import os\n",
        "\n",
        "INFERENCE_ENDPOINT = \"https://infer.roboflow.com\"\n",
        "API_KEY = \"rXUCtP2HyHKayj9DIr2F\"\n",
        "VIDEO = \"./video.mov\"\n",
        "\n",
        "prompts = [\n",
        "    \"person\",\n",
        "    \"something else\"\n",
        "]\n",
        "\n",
        "ACTIVE_PROMPT = \"person\""
      ],
      "metadata": {
        "id": "TEs25rA73qdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_image(image: str) -> dict:\n",
        "    image_data = Image.fromarray(image)\n",
        "\n",
        "    buffer = BytesIO()\n",
        "    image_data.save(buffer, format=\"JPEG\")\n",
        "    image_data = base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "    payload = {\n",
        "        \"api_key\": API_KEY,\n",
        "        \"subject\": {\n",
        "            \"type\": \"base64\",\n",
        "            \"value\": image_data\n",
        "        },\n",
        "        \"prompt\": prompts,\n",
        "    }\n",
        "\n",
        "    data = requests.post(INFERENCE_ENDPOINT + \"/clip/compare?api_key=\" + API_KEY, json=payload)\n",
        "\n",
        "    response = data.json()\n",
        "\n",
        "    highest_prediction = 0\n",
        "    highest_prediction_index = 0\n",
        "\n",
        "    for i, prediction in enumerate(response[\"similarity\"]):\n",
        "        if prediction > highest_prediction:\n",
        "            highest_prediction = prediction\n",
        "            highest_prediction_index = i\n",
        "\n",
        "    return prompts[highest_prediction_index]"
      ],
      "metadata": {
        "id": "cd2eoq-j4ww7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "results = []\n",
        "\n",
        "for i, frame in enumerate(sv.get_video_frames_generator(source_path=VIDEO, stride=10)):\n",
        "    print(\"Frame\", i)\n",
        "    label = classify_image(frame)\n",
        "\n",
        "    results.append(label)\n",
        "\n",
        "video_length = 10 * len(results)\n",
        "\n",
        "video_length = video_length / 24\n",
        "\n",
        "print(f\"Does this video contain a {ACTIVE_PROMPT}?\", \"yes\" if ACTIVE_PROMPT in results else \"no\")\n",
        "\n",
        "if ACTIVE_PROMPT in results:\n",
        "    print(f\"When does the {ACTIVE_PROMPT} first appear?\", round(results.index(ACTIVE_PROMPT) * 10 / 24, 0), \"seconds\")\n",
        "\n",
        "print(f\"For how long is the {ACTIVE_PROMPT} visible?\", round(results.count(ACTIVE_PROMPT) * 10 / 24, 0), \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JszMgm0I4-Ya",
        "outputId": "0276f20f-ee47-407c-9120-757082a728de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame 0\n",
            "Frame 1\n",
            "Frame 2\n",
            "Frame 3\n",
            "Frame 4\n",
            "Frame 5\n",
            "Frame 6\n",
            "Frame 7\n",
            "Frame 8\n",
            "Frame 9\n",
            "Frame 10\n",
            "Frame 11\n",
            "Frame 12\n",
            "Frame 13\n",
            "Frame 14\n",
            "Frame 15\n",
            "Frame 16\n",
            "Frame 17\n",
            "Frame 18\n",
            "Frame 19\n",
            "Frame 20\n",
            "Frame 21\n",
            "Frame 22\n",
            "Frame 23\n",
            "Frame 24\n",
            "Frame 25\n",
            "Frame 26\n",
            "Frame 27\n",
            "Frame 28\n",
            "Frame 29\n",
            "Frame 30\n",
            "Frame 31\n",
            "Frame 32\n",
            "Frame 33\n",
            "Frame 34\n",
            "Frame 35\n",
            "Frame 36\n",
            "Frame 37\n",
            "Frame 38\n",
            "Frame 39\n",
            "Frame 40\n",
            "Frame 41\n",
            "Frame 42\n",
            "Frame 43\n",
            "Frame 44\n",
            "Does this video contain a person? yes\n",
            "When does the person first appear? 0.0 seconds\n",
            "For how long is the person visible? 16.0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Video analysis using HF transformers"
      ],
      "metadata": {
        "id": "lspjqdZiseM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless pytube\n",
        "!pip install moviepy\n",
        "!pip install pytube\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eccloViGsroe",
        "outputId": "16d94bc3-4113-459b-d62a-1d5aebdbb081"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python-headless) (1.23.5)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.23.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.1)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.8)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "! pip install transformers -q"
      ],
      "metadata": {
        "id": "CCH-cKV7z4SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings,logging\n",
        "warnings.simplefilter('ignore')\n",
        "logging.disable(logging.WARNING)"
      ],
      "metadata": {
        "id": "KO4CuOskz0kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import pipeline\n",
        "caption = pipeline('image-to-text')\n"
      ],
      "metadata": {
        "id": "uAs1MeNjz9tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pytube import YouTube\n",
        "import imageio\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "# Define the YouTube video URL\n",
        "youtube_url = \"https://www.youtube.com/watch?v=YLslsZuEaNE\"\n",
        "\n",
        "# Define the folder where you want to store the video\n",
        "output_folder = \"/content\"\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Download the YouTube video\n",
        "yt = YouTube(youtube_url)\n",
        "stream = yt.streams.get_highest_resolution()\n",
        "video_file = os.path.join(output_folder, f\"{yt.title}.mp4\")\n",
        "stream.download(output_path=output_folder, filename=yt.title)\n",
        "\n",
        "# The zip file can be downloaded using the Colab interface.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "3BXB0ku6suSN",
        "outputId": "0f92b54b-8a15-4706-8c43-10ff27abb148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/1 Minute Video - Doggie'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pytube import YouTube\n",
        "import imageio\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "\n",
        "\n",
        "# Verify if the video file exists after download\n",
        "video_file=\"/content/1 Minute Video - Doggie\"\n",
        "\n",
        "if os.path.exists(video_file):\n",
        "    print(f\"Video download successful: {video_file}\")\n",
        "\n",
        "    # Now, you can proceed with the video-to-images conversion using moviepy\n",
        "    clip = VideoFileClip(video_file)\n",
        "    frame_count = 8\n",
        "\n",
        "    # Create a folder to store frames\n",
        "    frames_folder = os.path.join(output_folder, 'video_frames')\n",
        "    os.makedirs(frames_folder, exist_ok=True)\n",
        "\n",
        "    for frame in clip.iter_frames(fps=30):  # Adjust the frame rate (fps) as needed\n",
        "        frame_count += 1\n",
        "        image_file = os.path.join(frames_folder, f\"frame_{frame_count:04d}.jpg\")\n",
        "        imageio.imwrite(image_file, frame)\n",
        "\n",
        "    # Print a message when the conversion is complete\n",
        "    print(f\"Video conversion complete. {frame_count} frames saved as images in {frames_folder}\")\n",
        "\n",
        "    # Optionally, you can create a zip file of the images for easy download\n",
        "    import shutil\n",
        "\n",
        "    shutil.make_archive(frames_folder, 'zip', frames_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvWoLuIuvJre",
        "outputId": "095cf731-7dbb-48ec-bd5b-323025a7b5d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video download successful: /content/1 Minute Video - Doggie\n",
            "Video conversion complete. 1802 frames saved as images in /content/video_frames\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, process the images with the caption pipeline and save the results\n",
        "import os\n",
        "from pytube import YouTube\n",
        "import imageio\n",
        "from moviepy.editor import VideoFileClip\n",
        "output_folder=\"/content\"\n",
        "frames_folder = os.path.join(output_folder, 'video_frames')\n",
        "caption_output_folder = os.path.join(output_folder, 'caption_output')\n",
        "os.makedirs(caption_output_folder, exist_ok=True)\n",
        "frame_count = 20\n",
        "for frame_num in range(1, frame_count + 1):\n",
        "  input_image = os.path.join(frames_folder, f\"frame_{frame_num:04d}.jpg\")\n",
        "  output_caption_file = os.path.join(caption_output_folder, f\"caption_frame_{frame_num:04d}.txt\")\n",
        "\n",
        "        # Call the caption pipeline to generate captions from images\n",
        "  caption_result = caption(input_image)\n",
        "\n",
        "        # Extract the caption text from the result\n",
        "  print(caption_result)\n",
        "  caption_text = None\n",
        "  for key in caption_result[0].keys():\n",
        "    if 'caption' in key.lower():\n",
        "      caption_text = caption_result[0][key]\n",
        "      break\n",
        "\n",
        "        # Save the caption text to a text file\n",
        "    if caption_text:\n",
        "      with open(output_caption_file, 'w') as caption_file:\n",
        "        caption_file.write(caption_text)\n",
        "\n",
        "      # Optionally, you can create a zip file of the caption output\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive(caption_output_folder, 'zip', caption_output_folder)\n",
        "\n",
        "    # The zip file can be downloaded using the Colab interface.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "gWIjJKb32bLP",
        "outputId": "d7f2d0cd-884c-4ec5-c9ca-44a6eacc1cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'generated_text': 'a dog is playing with a ball in a yard '}]\n",
            "[{'generated_text': 'a dog is playing with a ball in a yard '}]\n",
            "[{'generated_text': 'a dog is playing with a frisbee in a yard '}]\n",
            "[{'generated_text': 'a dog is playing with a frisbee in a yard '}]\n",
            "[{'generated_text': 'a dog is playing with a frisbee in the yard '}]\n",
            "[{'generated_text': 'a dog playing with a frisbee in a yard '}]\n",
            "[{'generated_text': 'a small dog playing with a frisbee in a yard '}]\n",
            "[{'generated_text': 'a small dog playing with a ball in a yard '}]\n",
            "[{'generated_text': 'a small dog playing with a frisbee in a yard '}]\n",
            "[{'generated_text': 'a dog is playing with a ball in the yard '}]\n",
            "[{'generated_text': 'a dog is playing with a frisbee in the yard '}]\n",
            "[{'generated_text': 'a dog is playing with a frisbee in the yard '}]\n",
            "[{'generated_text': 'a dog is playing with a frisbee in the yard '}]\n",
            "[{'generated_text': 'a dog is playing with a frisbee in the yard '}]\n",
            "[{'generated_text': 'a small dog standing in the grass with a frisbee '}]\n",
            "[{'generated_text': 'a dog standing in the grass with a frisbee '}]\n",
            "[{'generated_text': 'a dog standing in the grass with a frisbee '}]\n",
            "[{'generated_text': 'a dog standing in the grass with a frisbee '}]\n",
            "[{'generated_text': 'a small dog standing in the grass next to a green fire hydrant '}]\n",
            "[{'generated_text': 'a small dog standing next to a ball in a yard '}]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/caption_output.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}